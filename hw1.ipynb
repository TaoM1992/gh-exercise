{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPpPATF6Iq08qp4L+qb4755",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15980cd19a0e4ff8ba960d019198471a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97790a3e42b744818e8ebc1bd0e70044",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3d9dabc6fc74dd69e948b2a0eacf482",
              "IPY_MODEL_4a64faf7cc0c4c2bbc335f0a7e479504"
            ]
          }
        },
        "97790a3e42b744818e8ebc1bd0e70044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3d9dabc6fc74dd69e948b2a0eacf482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_448ece6ce65c482e971f1584148cbb24",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5c9af3f4d024cc7a5a75dc43989a946"
          }
        },
        "4a64faf7cc0c4c2bbc335f0a7e479504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1774ca77a68642a795582a5a297ed395",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [05:13&lt;00:00, 156.87s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c1a20c300af4c7f8138cb486d84eef9"
          }
        },
        "448ece6ce65c482e971f1584148cbb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5c9af3f4d024cc7a5a75dc43989a946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1774ca77a68642a795582a5a297ed395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c1a20c300af4c7f8138cb486d84eef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaoM1992/gh-exercise/blob/master/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RADL3uueRmLx"
      },
      "source": [
        "# Homework 1\n",
        "#### Shiqi Tao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_SsFBuDRhwf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3d46XnYRpol"
      },
      "source": [
        "train = pd.read_csv('book_ratings_train_v2.csv')\n",
        "test = pd.read_csv('book_ratings_test_v2.csv')"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMHYfOTpSgip",
        "outputId": "bf29d915-6d97-4873-b3da-5705a145c05e"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((682295, 20), (29877, 20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g617a6aqSluL"
      },
      "source": [
        "#### 1. First create a dictionary for users and books, then do the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSkra9QVSgtN"
      },
      "source": [
        "user = train.user_id.unique()\n",
        "book = train.isbn.unique()\n",
        "\n",
        "user_dic = dict()\n",
        "for i,u in enumerate(user):\n",
        "    user_dic[u] = i \n",
        "\n",
        "book_dic = dict()\n",
        "for i,b in enumerate(book):\n",
        "    book_dic[b] = i "
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjoqieCzSgv8"
      },
      "source": [
        "num_users, num_books = len(user), len(book_dic)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECLj0w6rKvAa"
      },
      "source": [
        "for id in test.user_id.unique():\n",
        "  if id not in user:\n",
        "    test = test.drop(test[test.user_id==id].index)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaPWQMP6Ljv1"
      },
      "source": [
        "for b in test.isbn.unique():\n",
        "  if b not in book:\n",
        "    test = test.drop(test[test.isbn==b].index)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPHl99ILSxGL"
      },
      "source": [
        "- Create a DataSet class that outputs the user and book indices in a single tensor (in preparation for input into an nn.Embedding layer) and another tensor with the book rating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "ywRKA1a1VWM8",
        "outputId": "2cbb37c1-3363-47d1-a0ff-1ad6f6b11a38"
      },
      "source": [
        "train['quality'] = train.map(lambda x: 1 if train.rating>4 else 0)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-248-a76b1b680cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6nNCIL2Sgyl"
      },
      "source": [
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        user_idx = user_dic[row['user_id']]\n",
        "        book_idx = book_dic[row['isbn']]\n",
        "        \n",
        "        x1 = torch.tensor(user_idx)\n",
        "        x2 = torch.tensor(book_idx)\n",
        "        \n",
        "        y = torch.tensor(row['rating']).float()\n",
        "        y_bin = torch.tensor(row['rating']>4).float()\n",
        "        \n",
        "        return x1, x2, y, y_bin"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5nawj5uS2k0"
      },
      "source": [
        "- Create a DataLoader for the training data and the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7MQSS7ySg1H"
      },
      "source": [
        "rating_train_ds = RatingDataset(train)\n",
        "rating_train_dl = DataLoader(rating_train_ds, batch_size=1000, shuffle=True)"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5LvRtnpSg30"
      },
      "source": [
        "rating_test_ds = RatingDataset(test)\n",
        "rating_test_dl = DataLoader(rating_test_ds, batch_size=1000, shuffle=True)"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89fmSKegS-IZ"
      },
      "source": [
        "#### 2. Create three different classes of models using nn.Module. You will need a second DataSet class for the third model.\n",
        "\n",
        "- A model which predicts the rating a user will give to a book using Matrix Factorization (similar to what you did before in Dr. Interian’s course)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvlMZ8E8S7jb"
      },
      "source": [
        "class MF_rating_v1(nn.Module):\n",
        "    def __init__(self, num_users, num_books, emb_size=50):\n",
        "        super(MF_rating_v1, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.book_emb = nn.Embedding(num_books, emb_size)\n",
        "        # initlializing weights\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.book_emb.weight.data.uniform_(0,0.05)\n",
        "        \n",
        "    def forward(self, u, b):\n",
        "        u = self.user_emb(u)\n",
        "        b = self.book_emb(b)\n",
        "        return (u*b).sum(1)   "
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlxoEBSNTDxv"
      },
      "source": [
        "- A model which predicts the rating a user will give to a book by embedding both the book and the user as 50-dimensional features, followed by a linear layers (Hint: it will look like nn.Linear(100, 1))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_83CiUJS7nY"
      },
      "source": [
        "class MF_rating_v2(nn.Module):\n",
        "    def __init__(self, num_users, num_books, emb_size=50):\n",
        "        super(MF_rating_v2, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.book_emb = nn.Embedding(num_books, emb_size)\n",
        "        # initlializing weights\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.book_emb.weight.data.uniform_(0,0.05)\n",
        "        self.linear = nn.Linear(emb_size * 2, 1)\n",
        "        \n",
        "    def forward(self, u, v):\n",
        "        u = self.user_emb(u)\n",
        "        v = self.book_emb(v)\n",
        "        x = torch.cat((u, v), dim=1)\n",
        "        x = self.linear(x)\n",
        "        return torch.squeeze(x)"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BVMDLgWTIRv"
      },
      "source": [
        "- A model which predicts the rating a user will give to a book by embedding both the book and the user in some feature space (dimension up to you) and by including at least two other features from the dataset (such as age, location, year of publication, etc.). Note that for categorical variables you will need to use more embedding layers! Feel free to use any techniques we learned last week in this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ityw0Q94S7qX"
      },
      "source": [
        "age = train.age.unique()\n",
        "yp = train.year_of_publication.unique()\n",
        "\n",
        "age_dic = dict()\n",
        "for i,a in enumerate(age):\n",
        "    age_dic[a] = i \n",
        "\n",
        "yp_dic = dict()\n",
        "for i,y in enumerate(yp):\n",
        "    yp_dic[y] = i "
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zhga9MYS7tK"
      },
      "source": [
        "num_age, num_yp = len(age), len(yp)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh_n7LxQQ4bR",
        "outputId": "db6a0059-85d8-4a50-d728-ac861cddf3d0"
      },
      "source": [
        "num_age, num_yp"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOZPZdcyS7v4"
      },
      "source": [
        "class RatingDataset_v2(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        user_idx = user_dic[row['user_id']]\n",
        "        book_idx = book_dic[row['isbn']]\n",
        "        age_idx = age_dic[row['age']]\n",
        "        yp_idx = yp_dic[row['year_of_publication']]\n",
        "        \n",
        "        x1 = torch.tensor(user_idx)\n",
        "        x2 = torch.tensor(book_idx)\n",
        "        x3 = torch.tensor(age_idx)\n",
        "        x4 = torch.tensor(yp_idx)\n",
        "        \n",
        "        y = torch.tensor(row['rating']).float()\n",
        "        y_bin = torch.tensor(row['rating']>4).float()\n",
        "        return x1, x2, x3, x4, y, y_bin"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZ1YEgSS7yf"
      },
      "source": [
        "class MF_rating_v3(nn.Module):\n",
        "    def __init__(self, num_users, num_books, num_age, num_yp, emb_size=50):\n",
        "        super(MF_rating_v3, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.book_emb = nn.Embedding(num_books, emb_size)\n",
        "        self.age_emb = nn.Embedding(num_age, emb_size)\n",
        "        self.yp_emb = nn.Embedding(num_yp, emb_size)\n",
        "        # initlializing weights\n",
        "        self.user_emb.weight.data.uniform_(0,0.05)\n",
        "        self.book_emb.weight.data.uniform_(0,0.05)\n",
        "        self.linear = nn.Linear(emb_size * 4, 1)\n",
        "        \n",
        "    def forward(self, u, v, a, yp):\n",
        "        u = self.user_emb(u)\n",
        "        v = self.book_emb(v)\n",
        "        a = self.age_emb(a)\n",
        "        yp = self.yp_emb(yp)\n",
        "        x = torch.cat((u, v, a, yp), dim=1)\n",
        "        x = self.linear(x)\n",
        "        return torch.squeeze(x)"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82cDCIcgTV3X"
      },
      "source": [
        "#### 3. Initialize each of the three models and pass one batch through them to make sure they are working properly.\n",
        "- MF_rating_v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "274a7lt-TTRg",
        "outputId": "f4bd0d0f-2352-4421-b391-3ff70c66324f"
      },
      "source": [
        "u, b, y, y_bin = next(iter(rating_train_dl))\n",
        "m1 = MF_rating_v1(num_users, num_books)\n",
        "optimizer = optim.Adam(m1.parameters(), lr = 0.01)\n",
        "\n",
        "\n",
        "y_pred = m1(u, b)\n",
        "nn.MSELoss()(y_pred, y)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(19.3479, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZyfjkhyTdhp"
      },
      "source": [
        "- MF_rating_v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw6x_6YtTTUT",
        "outputId": "b13935f1-5581-4881-c6a4-ec967bee5c2f"
      },
      "source": [
        "u, b, y, y_bin = next(iter(rating_train_dl))\n",
        "m2 = MF_rating_v2(num_users, num_books)\n",
        "optimizer = optim.Adam(m2.parameters(), lr = 0.01)\n",
        "\n",
        "\n",
        "y_pred = m2.forward(u, b)\n",
        "nn.MSELoss()(y_pred, y)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(21.4517, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAHQCUMpTkC4"
      },
      "source": [
        "- MF_rating_v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-0hfAtvTTXb"
      },
      "source": [
        "rating_train_ds_v2 = RatingDataset_v2(train)\n",
        "rating_train_dl_v2 = DataLoader(rating_train_ds_v2, batch_size=1000, shuffle=True)"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7yU_kn9TTZ-",
        "outputId": "2a7c0c6d-fed9-4125-9f1a-550e7afe19dc"
      },
      "source": [
        "u, b, a, yp, y, y_bin = next(iter(rating_train_dl_v2))\n",
        "m3 = MF_rating_v3(num_users, num_books, num_age, num_yp)\n",
        "optimizer = optim.Adam(m3.parameters(), lr = 0.01)\n",
        "\n",
        "\n",
        "y_pred = m3.forward(u, b, a, yp)\n",
        "nn.MSELoss()(y_pred, y)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18.0202, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7roukNGTqbu"
      },
      "source": [
        "4. Train each of the models for this regression task using an appropriate Loss function for at least two epochs. At the end of each epoch, print the accuracy of your model in predicting whether a user will rate a book as “good” (rating above 4) or as “bad” (rating 4 or below) for both the training and test sets.\n",
        "\n",
        "- For context, I achieved around 57% percent accuracy on the test set after 5 epochs and 20 minutes on my laptop using the second model. I used a batch size of 10000 and Adam optimization with a learning rate of 0.01."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLTj5R_PTr1o"
      },
      "source": [
        "- You will not be graded on model performance, just being able to train the model and print the accuracy. The dataset is rather large, so if you are interested in pushing the performance and trying other methods I suggest using Google Colab or Kaggle GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT_c7cChXJN6"
      },
      "source": [
        "- MF_rating_v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "15980cd19a0e4ff8ba960d019198471a",
            "97790a3e42b744818e8ebc1bd0e70044",
            "f3d9dabc6fc74dd69e948b2a0eacf482",
            "4a64faf7cc0c4c2bbc335f0a7e479504",
            "448ece6ce65c482e971f1584148cbb24",
            "e5c9af3f4d024cc7a5a75dc43989a946",
            "1774ca77a68642a795582a5a297ed395",
            "0c1a20c300af4c7f8138cb486d84eef9"
          ]
        },
        "id": "Xe64Xo2nTTdE",
        "outputId": "fe503ab3-39e1-40de-972e-76f679e77458"
      },
      "source": [
        "m1 = MF_rating_v1(num_users, num_books)\n",
        "optimizer = optim.Adam(m1.parameters(), lr = 0.001)\n",
        "\n",
        "avg_train_1 = []\n",
        "avg_val_1 = []\n",
        "\n",
        "for epoch in tqdm(range(2)):\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    m1.train()\n",
        "    for u, b, y, y_bin in rating_train_dl:\n",
        "        \n",
        "        \n",
        "        \n",
        "        y_pred = m1(u, b)\n",
        "        loss = F.binary_cross_entropy(y_pred, y)\n",
        "        train_loss += loss.item())\n",
        "        y_pred_ = (y_pred > 0.5).long()\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    avg_train_1.append(sum(train_losses) / len(train_losses))\n",
        "        \n",
        "        y_hat = m1(u, b)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += x.size(0)*loss.item()\n",
        "        total += x.size(0)\n",
        "    train_loss = total_loss/total\n",
        "    \n",
        "    for u, b, y in rating_test_dl:\n",
        "        m1.eval()\n",
        "        \n",
        "        y_pred = m1(u, b)\n",
        "        loss = lossFun(y_pred, y)\n",
        "        \n",
        "        avg_val_1.append(loss.item())\n",
        "    print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))  "
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15980cd19a0e4ff8ba960d019198471a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX6k3aTyXONL"
      },
      "source": [
        "- MF_rating_v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJTV6ClPTuPY"
      },
      "source": [
        "lossFun = nn.L1Loss()\n",
        "m2 = MF_rating_v1(num_users, num_books)\n",
        "optimizer = optim.Adam(m2.parameters(), lr = 0.001)\n",
        "\n",
        "avg_train_2 = []\n",
        "avg_val_2 = []\n",
        "\n",
        "for epoch in tqdm(range(2)):\n",
        "    train_losses = []\n",
        "    for u, b, y in rating_train_dl:\n",
        "        \n",
        "        m2.train()\n",
        "        \n",
        "        y_pred = m2(u, b)\n",
        "        loss = lossFun(y_pred, y)\n",
        "        train_losses.append(loss.item())\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    avg_train_2.append(sum(train_losses) / len(train_losses))\n",
        "    \n",
        "    for u, b, y in rating_test_dl:\n",
        "        m2.eval()\n",
        "        \n",
        "        y_pred = m2(u, b)\n",
        "        loss = lossFun(y_pred, y)\n",
        "        \n",
        "        avg_val_2.append(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHPApkgFXRQj"
      },
      "source": [
        "- MF_rating_v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FTVn--wXQmK"
      },
      "source": [
        "lossFun = nn.L1Loss()\n",
        "m3 = MF_rating_v3(num_users, num_books)\n",
        "optimizer = optim.Adam(m3.parameters(), lr = 0.001)\n",
        "\n",
        "avg_train_3 = []\n",
        "avg_val_3 = []\n",
        "\n",
        "for epoch in tqdm(range(2)):\n",
        "    train_losses = []\n",
        "    for u, b, y in rating_train_dl_v2:\n",
        "        \n",
        "        m1.train()\n",
        "        \n",
        "        y_pred = m3(u, b)\n",
        "        loss = lossFun(y_pred, y)\n",
        "        train_losses.append(loss.item())\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    avg_train_3.append(sum(train_losses) / len(train_losses))\n",
        "    \n",
        "    for u, b, y in rating_test_dl_v2:\n",
        "        m3.eval()\n",
        "        \n",
        "        y_pred = m3(u, b)\n",
        "        loss = lossFun(y_pred, y)\n",
        "        \n",
        "        avg_val_3.append(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVCb4_6mTxFH"
      },
      "source": [
        "5. Pick one of the model architecture and use it directly predict whether a user will rate a book as “good” or “bad” (rather than through regression onto the rating). Constrast with the accuracy you obtained in the previous problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlGyQh5hTuYK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOTBhsGpTuag"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}